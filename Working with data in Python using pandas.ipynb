{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with data in Python using pandas \n",
    "## *Data Skills for Science*\n",
    "\n",
    "***\n",
    "\n",
    "Welcome to this introductory workshop on the using the Python programming language to work with data, designed for the science graduate student. In this workshop, we will cover: \n",
    "\n",
    "* learn about the pandas library\n",
    "* import data into a DataFrame\n",
    "* describe DataFrames and how to manipulate data\n",
    "\n",
    "\n",
    "\n",
    "### Acknowledgments and copyright\n",
    "This workshop was developed by Roger Reka (University of Windsor) for the 2019 Fall Leddy Library Scholars Series. This material is licensed under a [Creative Commons CC-BY 4.0 license](https://creativecommons.org/licenses/by/4.0/); you are free to re-use this material and/or adapt it for your own needs.\n",
    "\n",
    "Some of the material in this workshop is adapted from the Data Carpentry [*Data Analysis and Visualization in Python for Ecologists*](https://datacarpentry.org/python-ecology-lesson/) lesson, which is also licensed with a CC-BY license.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas in Python\n",
    "pandas is a library package for working with data in Python. The [Python Data Analysis Library (pandas)](https://pandas.pydata.org/) provides data structures, produces high quality plots with matplotlib and integrates nicely with other libraries that use NumPy (which is another Python library) arrays.\n",
    "\n",
    "pandas comes installed with the Anaconda distribution, so all we need to do is import it into the current session. We import libraries by using the `import` command, and use the `as` command to give the library a nickname throughout the session. By convention, we import pandas as `pd`, so that we don't have to type out 'pandas' every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # import the pandas library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get working with some data. For this workshop, we're going to use the Portal Project Teaching dataset of ecology data — this is the same dataset we used in our R workshop. \n",
    "\n",
    "To read data into Python with pandas, we use the `read_csv` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/surveys.csv\")  # read the csv into pandas, and assign it to an object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, that when we create an object, Python doesn't produce any output. To see the output, you'll need to call the object name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've just created a pandas DataFrame.  A DataFrame is a 2-dimensional data structure (tabular) that can store data of different types in the columns. It is similar to a spreadsheet. DataFrames will become the base for all of our further analysis and work with data in Python. We'll describe DataFrames as we work along.\n",
    "\n",
    "To only see the first few rows of a DataFrame, we can use the method `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exploring the DataFrame\n",
    "Let's explore and describe the DataFrame that we've just created. \n",
    "\n",
    "As with any other object, we can use `type()` to determine the object type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't surprising. Our object, `df` is a DataFrame. Let's now see what types the data within the DataFrame are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. A few things to note. \n",
    "\n",
    "First, all the data within a column must be of the same type.\n",
    "\n",
    "Second, pandas uses different names for the data types than Python, though they refer to the same data type. In pandas:\n",
    "\n",
    "`object` is the same as `str`\n",
    "<br>\n",
    "`int64` is the same as `int`\n",
    "<br>\n",
    "`float64` is the same as `float`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Challenge 1</b> \n",
    "</div>\n",
    "\n",
    "There are many helpful methods and attributes for exploring DataFrames. Using the our DataFrame `df`, try out the following methods and attributes:\n",
    "\n",
    "1. `surveys_df.columns`\n",
    "2. `surveys_df.shape` Take note of the output of shape - what format does it return the shape of the DataFrame in?\n",
    "3. `surveys_df.head()` Also, what does `surveys_df.head(15)` do?\n",
    "4. `surveys_df.tail()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "We’ve read our data into Python. Next, let’s perform some quick summary statistics to learn more about the data that we’re working with. We might want to know how many animals were collected in each site, or how many of each species were caught. We can perform summary stats quickly using groups. But first we need to figure out what we want to group by.\n",
    "\n",
    "Let’s begin by exploring our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s get a list of all the species. The `.unique()` method tells us all of the unique values in the `species_id` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['species_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['species_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Challenge 2</b> \n",
    "</div>\n",
    "\n",
    "1. Create a list of unique site ID’s (“plot_id”) found in the surveys data. Call it `site_names`. How many unique sites are there in the data? How many unique species are in the data?\n",
    "\n",
    "2. What is the difference between `len(site_names)` and `df['plot_id'].nunique()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Explore the DataFrame columns\n",
    "\n",
    "In addition to the methods and functions for describing the DataFrames, there are a useful tools for describing **columns** within a DataFrame.\n",
    "\n",
    "We can call these methods by first **subsetting** the column of interest. We do this in a similar fashion as we did with lists – we use the square brackets along with the column name. For example, we might want to calculate the average weight of all individuals per site.\n",
    "\n",
    "We can calculate basic statistics for all records in a single column using the syntax below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of methods for pandas columns which we can use to help us understand the data in the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "### Grouping\n",
    "\n",
    "But if we want to summarize by one or more variables, for example sex, we can use Pandas’ .groupby method. Once we’ve created a groupby DataFrame, we can quickly calculate summary statistics by a group of our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_data = df.groupby('sex')  # Group data by sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas function `.describe()` will return descriptive stats including: mean, median, max, min, std and count for a particular column in the data. Pandas’ describe function will only return summary values for columns containing numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Set no restrictions on the number of columns visible in JN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.describe()  # Summary statistics for all numeric columns by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_data.mean()  # Provide the mean for each numeric column by sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Challenge 3</b> \n",
    "</div>\n",
    "\n",
    "1. How many recorded individuals are female `F` and how many male `M`\n",
    "2. What happens when you group by two columns using the following syntax and then grab mean values:\n",
    "> `grouped_data2 = df.groupby(['plot_id','sex'])` <br>\n",
    "> `grouped_data2.mean()`\n",
    "\n",
    "3. Summarize weight values for each site in your data. HINT: you can use the following syntax to only create summary statistics for one column in your data `by_site['weight'].describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "We can quickly create summary counts in pandas by combining functions together. Here we'll use the `.groupby()` method and the `.count()` method to count the number of samples for each species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('species_id')['record_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is such a useuful task, there is a built-in method for this task: `.value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['species_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing the pandas DataFrame\n",
    "Sometimes we don't need to work with the entre DataFrame, but only some elements of it.\n",
    "\n",
    "We use square brackets `[]` to select a subset of a Python object. For example, we can select all data from a column named `species_id` from the `df` DataFrame by name. There are two ways to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['species_id']  # Method 1: select a 'subset' of the data using the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.species_id  # Method 2: use the column name as an 'attribute'; gives the same output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a new object that contains only the data within the species_id column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys_species = df['species_id']  # Creates an object, surveys_species, that only contains the `species_id` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "surveys_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass a list of column names too, as an index to select columns in that order. This is useful when we need to reorganize our data.\n",
    "\n",
    "NOTE: If a column name is not contained in the DataFrame, an exception (error) will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['species_id', 'plot_id']]  # Select the species and plot columns from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['plot_id', 'species_id']]  # What happens when you flip the order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['speciess']  # What happens if you ask for a column that doesn't exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python tells us what type of error it is in the traceback, at the bottom it says `KeyError: 'speciess'` which means that `speciess` is not a valid column name (nor a valid key in the related Python data type dictionary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing and subseting rows in pandas\n",
    "\n",
    "Slicing using the `[]` operator selects a set of rows and/or columns from a DataFrame. To slice out a set of rows, you use the following syntax: `data[start:stop]`. When slicing in pandas the start bound is included in the output. The stop bound is one step BEYOND the row you want to select. So if you want to select rows 0, 1 and 2 your code would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:3]  # Select rows 0, 1, 2 (row 3 is not selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:5]  # Select the first 5 rows (rows 0, 1, 2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select specific ranges of our data in both the row and column directions. To select a subset of rows and columns from our DataFrame, we can use the `.iloc(rows, columns)` method. \n",
    "\n",
    "For example, we can select month, day and year (columns 2, 3 and 4 if we start counting at 1), like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:3, 1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we asked for a slice from 0:3. This yielded 3 rows of data. When you ask for 0:3, you are actually telling Python to start at index 0 and select rows 0, 1, 2 up to but not including 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Challenge 4</b> \n",
    "</div>\n",
    "\n",
    "Complete the following subsets and slices:\n",
    "\n",
    "1. Select the first three rows of the DataFrame.\n",
    "2. Select the first three rows of the DatatFrame, and only the record id and the hindfoot length columns.\n",
    "3. What happens when you execute `df[:-1]`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Subsetting Data using Criteria\n",
    "We can also select a subset of our data using criteria. For example, we can select all rows that have a year value of 2002:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.year == 2002]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can select all rows that do not contain the year 2002:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df.year != 2002]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also subset data using multiple criteria. When this is the case, we need to separate the criteria using parantheses `( )`. \n",
    "\n",
    "Combine the criteria using 'and' `&`, and 'or' `|`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df.year >= 1980) & (df.year <= 1985)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, the logical operators in Python:\n",
    "\n",
    "> Equals: `==`\n",
    "\n",
    "> Not equals: `!=`\n",
    "\n",
    "> Greater than, less than: `>` or `<`\n",
    "\n",
    "> Greater than or equal to `>=`\n",
    "\n",
    "> Less than or equal to `<=`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Challenge 5</b> \n",
    "</div>\n",
    "\n",
    "1. Select a subset of rows in the `df` DataFrame that contain data from the year 1999 and that contain weight values less than or equal to 8. How many rows did you end up with? What did your neighbor get?\n",
    "\n",
    "2. You can use the `.isin()` method in Python to query a DataFrame based upon a list of values as follows:\n",
    "\n",
    "> `df[df['species_id'].isin([listGoesHere])]`\n",
    "\n",
    "Use the `.isin()` function to find all plots that contain particular species in the DataFrame. How many records contain these values?\n",
    "\n",
    "* Experiment with other queries. Create a query that finds all rows with a weight value > or equal to 0.\n",
    "\n",
    "* The `~` symbol in Python can be used to return the OPPOSITE of the selection that you specify in Python. It is equivalent to is not in. Write a query that selects all rows with sex NOT equal to ‘M’ or ‘F’ in the “surveys” data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['species_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Adding and removing columns\n",
    "We can change the DataFrame by adding and removing columns. New columns can contain new data or we can rename columns.\n",
    "\n",
    "To add a column, call the DataFrame object and the new column name using the square brackets `[]`. Assign the new column some data.\n",
    "\n",
    "For example, the `weight` column contains weight in grams. Let's rename it to `weight_g` to be more specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight_g'] = df['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we've created the new column `weight_g` that contains all of the original data as `weight`. The original column is still there; let's delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a new column with completely new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['random'] = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not too useful, so let's delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Manipulating data\n",
    "With pandas, we can manipulate data across rows, columns and the entire DataFrame — all at once.\n",
    "\n",
    "For example, let's convert the weight, currently in grams, to kilograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight_kg'] = df['weight_g'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say there was a mistake in one of the species ID labels. In pandas, we can also manipulate strings.\n",
    "\n",
    "Let's replace the `DM` species ID with `DA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['species_id'] == 'DM']  # view all of the rows containing 'DM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['species_id'] = df['species_id'].str.replace('DM', 'DA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['species_id'] == 'DM']  # view all of the rows containing 'DM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['species_id'] == 'DO']  # view all of the rows containing 'DO'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
